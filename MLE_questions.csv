scenario,question,A,B,C,D,answer,extra
The number of accidents on a one mile stretch of the Pennsylvania turnpike is thought to be independent and have the same mean from week to week.  ,The distribution of the number for one week would then follow, An exponential distribution,A Poisson distribution, A discrete uniform distribution  ,A geometric distribution,A Poisson distribution,
The number of accidents on a one mile stretch of the Pennsylvania turnpike is thought to be independent and have the same mean from week to week.  ,"Data on the number of accidents is collected for each of five weeks and comes out to 2, 5, 2, 3, and 4 accidents.  If you want to estimate the mean number, λ, of accidents per week on this one mile stretch then the MLE would be the value of λ that maximizes",\(\frac{λ^{16} e^{-5λ}}{2!5!3!4!}\),-5 λ+16ln(λ),\( λ^{16} e^{-5λ}\),All of the above,All of the above,
"Twenty randomly selected adults over 50 years of age in Pennsylvania are asked if they have been vaccinated for shingles giving observations \(x_1, x_2, …, x_{20} (x_i = 1 \) if yes and 0 if no) of the random variables \( X_1,…,X_{20}\).  ",The random variable X7 would then follow a,Geometric distribution,Bernoulli distribution,Normal distribution,Poisson distribution,Bernoulli distribution,
"Twenty randomly selected adults over 50 years of age in Pennsylvania are asked if they have been vaccinated for shingles giving observations \(x_1, x_2, …, x_{20} (x_i = 1 \) if yes and 0 if no) of the random variables \( X_1,…,X_{20}\).  ","These observations are to be used to estimate the probability, θ, that a randomly selected Pennsylvanian over 50 has been vaccinated for shingles. To find the MLE of θ, you would","maximize \(\ θ^{\sum{xi}} (1-θ)^{\sum{1-xi}}\) over the possible vectors (x1, x2, …, x20)",maximize \(\ θ^{\sum{xi}} (1-θ)^{\sum{1-xi}}\) over the possible values of θ,"maximize \(\ θ^{\sum{xi}} (1-θ)^{\sum{1-xi}}\) over the possible values of θ & vectors (x1, x2, …, x20)",none of the above,maximize \(\ θ^{\sum{xi}} (1-θ)^{\sum{1-xi}}\) over the possible values of θ,
,"Suppose Y = the time (hours) it takes a programmer to complete and debug a computer program has the pdf \( f(y) = e ^{-(y-a)}\) for y > a (= 0 otherwise). Ten programs are assigned to be completed and the times to completion for each, Y1, Y2, …, Y10, are independent and identically distributed with the pdf, f, above.  The MLE of α would be then be the","mean of Y1, Y2, …, Y10","median of Y1, Y2, …, Y10","minimum of Y1, Y2, …, Y10","maximum of Y1, Y2, …, Y10","minimum of Y1, Y2, …, Y10",(solve using theory \(\tilde{n}\) or use the slider to the left) (programming note \(\tilde{n}\) slider is for value of p and shows
,"In Pennsylvania, some roads have a mile-marker every 10th of a mile, while others only have mile-markers every mile.  A car is driving east and breaks down.  The driver decides to push his car to the next mile marker in that direction so it will be easy for a tow truck to find him when he calls for emergency service.  A tow service gets a call that a driver is stranded after pushing his car \(\frac{1}{20}\) of a mile.  What is the MLE of the type of mile-markers on that road (markers every 10th mile or markers every mile)?",every 10th of a mile,every mile,every \(\frac{1}{20}\) th of a mile,every \(\frac{1}{10}\) th of a mile,every 10th of a mile,
,True or False:  Maximum Likelihood Estimator is unbiased. ,TRUE,FALSE,,,FALSE,
,Which of the following is a consequence of the invariance property of maximum likelihood (where θ is a parameter of the distribution of X)?,The MLE of log(θ) is the log of the MLE of θ using data from observing X.,"Since θ is still a parameter of the distribution of Y = log(X), then data based observing Y will give the same MLE for θ as when the data are based on observing X.","Since ln(θ) is still a parameter of the distribution of Y = log(X), then the MLE of that parameter based on observing Y will give the log of the MLE of θ as when the data are based on observing X.",The MLE of log(θ) has the same variance as the MLE of θ.,The MLE of log(θ) is the log of the MLE of θ using data from observing X.,(solve using theory \(\tilde{n}\) or use the slider to the left) (programming note \(\tilde{n}\) slider is for value of p and shows
,"True or False: If X1, X2, …, Xn are i.i.d. with cdf F(x) = \( 1- e^{-θx}\) for x > 0 (= 0 otherwise) , then the MLE for θ can be found by finding the value of θ that maximizes multiplication F(xi)",TRUE,FALSE,,,FALSE,
"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters α and 1 so its pdf is given by \(f(x)=\begin{cases}ax^{a-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …,x_{20} \).",Which of the following will lead you to the maximum likelihood estimate of α?,Maximizing the likelihood with respect to the average of the data,Maximizing the likelihood with respect to α,Maximizing the log of the likelihood respect to α,Both b and c,,
"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters α and 1 so its pdf is given by \(f(x)=\begin{cases}ax^{a-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …,x_{20} \).","In this case, the log likelihood function is given by",\(20a +	\prod_{i=1}^{20}x_i\),\(20ln(a) + (a-1) \prod_{i=1}^{20}ln(x_i) \),\(\ln(a-1) \prod_{i=1}^{20}ln(x_i) \),\(a(a-1) \prod_{i=1}^{20}x_i \),\(20ln(a) + (a-1) \prod_{i=1}^{20}ln(x_i) \),
"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters α and 1 so its pdf is given by \(f(x)=\begin{cases}ax^{a-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …,x_{20} \).",The MLE of α in this problem would be, \(\hat{a} = \bar{x}\) (the average of the x values),\(\hat{a} = \frac{1}{\bar{x}}\) (the inverse of the average of the x values),\(\hat{a} = \bar{-ln(x)}\) (- the average of the log of the x values),\(\hat{a} = \frac{-1}{\bar{ln(x)}}\) (- the inverse of the average of the log of the x values),\(\hat{a} = \frac{-1}{\bar{ln(x)}}\) (- the inverse of the average of the log of the x values),(solve using theory \(\tilde{n}\) or use the slider to the left) (programming note \(\tilde{n}\) slider is for value of p and shows
"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  X1, X2,…, X20 where Xi = how many calls it takes before the ith likely voter agrees to take the survey.",What type of distribution does Xi have?,"Xi would be Bernoulli with an unknown probability, p, that Xi =1.",Xi would be Poisson with an unknown mean μ.,"Xi would be Binomial with n = 20 and an unknown probability, p, for the event in question.","Xi would be Geometric with an unknown probability, p, for the event in question.","Xi would be Geometric with an unknown probability, p, for the event in question.",
"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  X1, X2,…, X20 where Xi = how many calls it takes before the ith likely voter agrees to take the survey.","For observations Xi = xi for i = 1, …20, the log likelihood function would be",\(\ln(1-p) \sum_{i=1}^{20}x_i+20\ln\left(\frac{p}{1-p}\right)\),\(\ln(p) \sum_{i=1}^{20}x_i - 20p - \sum_{i=1}^{20}x_i\ln\left(x_i ! \right)\),\(\sum_{i=1}^{20}\ln(\frac{20}{x_i}) +\ln\left(1-p \right) + \ln\left(\frac{p}{1-p}\right) \sum_{i=1}^{20}x_i\), \(\sum_{i=1}^{20}x_i-p\sum_{i=1}^{20}\ln\left(x_i!\right)\),\(\ln(1-p) \sum_{i=1}^{20}x_i+20\ln\left(\frac{p}{1-p}\right)\),
"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  X1, X2,…, X20 where Xi = how many calls it takes before the ith likely voter agrees to take the survey.",The MLE for p is then given by, \(\hat{p} = \bar{x}\) (the average of the observed x’s),\(\hat{p} = \text{max}\{x_i\}\) (the maximum of the observed x’s),\(\hat{p} = \frac{1}{\bar{x}}\) (the inverse of the average of the observed x’s),\(\hat{p} = \text{min}\{x_i\}\) (the minimum of the observed x’s),\(\hat{p} = \frac{1}{\bar{x}}\) (the inverse of the average of the observed x’s),(solve using theory \(\tilde{n}\) or use the slider to the left) (programming note \(\tilde{n}\) slider is for value of p and shows
"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  X1, X2,…, X20 where Xi = how many calls it takes before the ith likely voter agrees to take the survey.","Finally, to answer the polling company’s question about estimating how many random calls it must make on average per respondent using maximum likelihood, we would find the ",MLE of \(\frac{1}{p}\) which is \(\frac{1}{\hat{p}}  = \bar{x}\) (the average of the observed x’s),MLE of \(\frac{1}{p}\) which is \(\frac{1}{\hat{p}} = \frac{1} {\bar{x}} \) (where \(\bar{x}\) = the average of the observed x’s),MLE of the median m which is m ̃ (the median of the x’s),MLE of the derivative of the log likelihood,MLE of \(\frac{1}{p}\) which is \(\frac{1}{p}\)  = x (the average of the observed x’s),
"The time between earthquakes, X, depends on a parameter θ that is associated with the sensitivity of the hardware used to detect them so that X follows the pdf \(f(x)=\begin{cases}θx^{-θx} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)",What is the likelihood function?,\(f(x)=\begin{cases}ax^{a-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\),\( 774 θ^{10} e^{-5θ}\),\( θ^{10}x^5 e^{-5x}\),\( 5996910θ^{10}e^{-774θ}\),\( 5996910θ^{10}e^{-774θ}\),
"The time between earthquakes, X, depends on a parameter θ that is associated with the sensitivity of the hardware used to detect them so that X follows the pdf \(f(x)=\begin{cases}θx^{-θx} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)","What is , the MLE of θ?",77.4,\(\frac{1}{77.4}\),\(\frac{5996910}{774}\),\(\frac{5996910}{5!}\),\(\frac{1}{77.4}\),