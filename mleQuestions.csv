Index,scenario,question,optionCount,A,B,C,D,E,F,answer,hint
1,The number of accidents on a one mile stretch of the Pennsylvania turnpike is thought to be independent and have the same mean from week to week.  ,The distribution of the number for one week would then follow,4, An exponential distribution,A Poisson distribution, A discrete uniform distribution  ,A geometric distribution,,,A Poisson distribution,The number of rare events in a process with independent increments.
1,The number of accidents on a one mile stretch of the Pennsylvania turnpike is thought to be independent and have the same mean from week to week.  ,"Data on the number of accidents is collected for each of five weeks and comes out to 2, 5, 2, 3, and 4 accidents.  If you want to estimate the mean number, \(\lambda\), of accidents per week on this one mile stretch then the MLE would be the value of \(\lambda\) that maximizes",4,\(\frac{\lambda^{16} e^{-5\lambda}}{2!5!3!4!}\),\( -5\lambda+16ln(\lambda)\),\(\lambda^{16} e^{-5\lambda}\),All of the above,,,All of the above,How does rescaling or taking logarithms affect the maximization problem?
2,"Twenty randomly selected adults over 50 years of age in Pennsylvania are asked if they have been vaccinated for shingles giving observations \( x_1, x_2, …, x_{20} \ (x_i = 1 \text{ if yes and  0 if no} ) \) of the random variables \( X_1,…,X_{20}\).",The random variable \( X_7\) would then follow a,4,Geometric distribution,Bernoulli distribution,Normal distribution,Poisson distribution,,,Bernoulli distribution,Values can only be 0 or 1
2,"Twenty randomly selected adults over 50 years of age in Pennsylvania are asked if they have been vaccinated for shingles giving observations \( x_1, x_2, …, x_{20} \ (x_i = 1 \text{ if yes and 0 if no} ) \) of the random variables \( X_1,…,X_{20}\).","These observations are to be used to estimate the probability, \(\theta\), that a randomly selected Pennsylvanian over 50 has been vaccinated for shingles. To find the MLE of \(\theta\), you would",4,"maximize \(\theta^{\sum{x_i}} (1-\theta)^{\sum{1-x_i}}\) over the possible vectors \(\ (x_1, x_2, …, x_{20}) \)",maximize \(\theta^{\sum{x_i}} (1-\theta)^{\sum{1-x_i}}\) over the possible values of \(\theta\),"maximize \(\theta^{\sum{x_i}} (1-\theta)^{\sum{1-x_i}}\) over the possible values of \( \theta\) & vectors \(\ (x_1, x_2, …, x_{20}) \)",none of the above,,,maximize \(\theta^{\sum{x_i}} (1-\theta)^{\sum{1-x_i}}\) over the possible values of \(\theta\),What is the parameter and what are the data
3,The following will be independent questions.,"Suppose Y = the time (hours) it takes a programmer to complete and debug a computer program has the pdf \(\ f(y) = e ^{-(y-\alpha)} \text{ for y } > \alpha \text{ (= 0 otherwise)} \). Ten programs are assigned to be completed and the times to completion for each, \( Y_1, Y_2, …, Y_{10} \), are independent and identically distributed with the pdf, f, above.  The MLE of \(\alpha\) would be then be the",4,"mean of \( Y_1, Y_2, …, Y_{10} \)","median of \( Y_1, Y_2, …, Y_{10} \)","minimum of \( Y_1, Y_2, …, Y_{10} \)","maximum of \( Y_1, Y_2, …, Y_{10} \)",,,"minimum of \( Y_1, Y_2, …, Y_{10} \)",The pdf has no probability below \(\alpha\).
3,The following will be independent questions.,"In Pennsylvania, some roads have a mile-marker every tenth of a mile, while others only have mile-markers every mile.  A car is driving east and breaks down.  The driver decides to push his car to the next mile marker in that direction so it will be easy for a tow truck to find him when he calls for emergency service.  A tow service gets a call that a driver is stranded after pushing his car \(\frac{1}{20} \) of a mile.  What is the MLE of the type of mile-markers on that road (markers every tenth mile or markers every mile)?",3,every tenth of a mile,every mile,every \(\frac{1}{20}\) th of a mile,,,,every tenth of a mile,There are only two possible values for the parameter – which has a higher likelihood?
3,The following will be independent questions.,Which of the following is a consequence of the invariance property of maximum likelihood (where \(\theta\) is a parameter of the distribution of X )?,4,The MLE of \(\log( \theta ) \) is the log of the MLE of \(\theta\) using data from observing X.,"Since \(\theta\) is still a parameter of the distribution of Y = \(\log(X)\), then data based observing Y will give the same MLE for \(\theta\) as when the data are based on observing X.","Since \(\ln( \theta ) \)is still a parameter of the distribution of Y = \(\log(X)\), then the MLE of that parameter based on observing Y will give the log of the MLE of \(\theta\) as when the data are based on observing X.",The MLE of \(\log(\theta)\) has the same variance as the MLE of \(\theta\).,,,The MLE of \(\log( \theta ) \) is the log of the MLE of \(\theta\) using data from observing X.,The invariance property relates to one-to-one functions of a parameter.
4,The following will be TRUE or FALSE questions. ,True or False:  Maximum Likelihood Estimators are always unbiased.,2,TRUE,FALSE,,,,,FALSE,"As an example think about the MLE for \(\theta\), based on data from a Uniform(0, \(\theta\) ) distribution."
4,The following will be TRUE or FALSE questions. ,"True or False: If \( X_1, X_2, …, X_n \) are i.i.d. with cdf \(  F(x) = 1- e^{-θx} \text{ for x > 0 (= 0 otherwise) } \), then the MLE for \(\theta\) can be found by finding the value of \(\theta\) that maximizes \(\prod F(x_i) \)",2,TRUE,FALSE,,,,,FALSE,Remember that F is the cdf.
5,"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters \(\alpha\) and 1 so its pdf is given by \(f(x)=\begin{cases} \alpha x^{\alpha-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …, x_{20} \).",Which of the following will lead you to the maximum likelihood estimate of \(\alpha\) ?,6,a. Maximizing the likelihood with respect to the average of the data,b. Maximizing the likelihood with respect to \(\alpha\),c. Maximizing the log of the likelihood respect to the average of the data,d. Maximizing the log of the likelihood respect to \(\alpha\),Both a and c,Both b and d,Both b and d,"Since log is a monotonic function, its maximum occurs at the same point."
5,"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters \(\alpha\) and 1 so its pdf is given by \(f(x)=\begin{cases} \alpha x^{\alpha-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …, x_{20} \).","In this case, the log likelihood function is given by",4,\(20\alpha +\prod_{i=1}^{20}x_i\),\(20\ln(\alpha) + (\alpha-1) \prod_{i=1}^{20}ln(x_i) \),\(\ln(\alpha-1) \prod_{i=1}^{20}ln(x_i) \),\(\alpha(\alpha-1) \prod_{i=1}^{20}x_i \),,,\(20\ln(\alpha) + (\alpha-1) \prod_{i=1}^{20}ln(x_i) \),Write the likelihood function as a product and take logs
5,"In a mining operation, the proportion, X, of a mineral that is found in a sample piece of ore follows the Beta distribution with parameters \(\alpha\) and 1 so its pdf is given by \(f(x)=\begin{cases} \alpha x^{\alpha-1} & \text{ for } 0<x<1 \\ 0 & \text{otherwise}\end{cases}\)
Twenty sample ores are removed from the mine providing independent observations \( x_1, x_2, …, x_{20} \).",The MLE of \(\alpha\) in this problem would be,4, \(\hat{\alpha} = \bar{x}\) (the average of the x values),\(\hat{\alpha} =1/ \bar{x} \) (the inverse of the average of the x values),\(\hat{\alpha} = - \overline{ln(x)} \) (- the average of the log of the x values),\(\hat{a} = -1 \big{/} \overline{ln(x)}\) (- the inverse of the average of the log of the x values),,,\(\hat{a} = -1 \big{/} \overline{ln(x)}\) (- the inverse of the average of the log of the x values),Find a so l’= 0 and l” < 0 where l is the log likelihood and the derivative is w.r.t. \(\alpha\)
6,"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  \(X_1, X_2,…, X_{20}\) where \(X_i\) = how many calls it takes before the \(i^{th}\) likely voter agrees to take the survey after the previous likely voter takes the survey.",What type of distribution does \(X_i\) have?,4,"\(X_i \) would be Bernoulli with an unknown probability, p, that \(X_i \) =1",\(X_i \) would be Poisson with an unknown mean \(\mu\),"\(X_i \) would be Binomial with n = 20 and an unknown probability, p, for the event in question","\(X_i \) would be Geometric with an unknown probability, p, for the event in question",,,"\(X_i \) would be Geometric with an unknown probability, p, for the event in question",We are modeling the number of trials until the first success.
6,"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  \(X_1, X_2,…, X_{20}\) where \(X_i\) = how many calls it takes before the \(i^{th}\) likely voter agrees to take the survey after the previous likely voter takes the survey.","For observations \(X_i = x_i \) for i = 1, …20, the log likelihood function would be",4,\(\ln(1-p) \sum_{i=1}^{20}x_i+20\ln\left(\frac{p}{1-p}\right)\),\(\ln(p) \sum_{i=1}^{20}x_i - 20p - \sum_{i=1}^{20}\ln\left(x_i ! \right)\),\(\sum_{i=1}^{20}\ln(\binom{20}{x_i}) +\ln\left(1-p \right) + \ln\left(\frac{p}{1-p}\right) \sum_{i=1}^{20}x_i\),\(\sum_{i=1}^{20}x_i-p\sum_{i=1}^{20}\ln\left(x_i!\right)\),,,\(\ln(1-p) \sum_{i=1}^{20}x_i+20\ln\left(\frac{p}{1-p}\right)\),The \(X_i’s\) follow a geometric distribution.
6,"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  \(X_1, X_2,…, X_{20}\) where \(X_i\) = how many calls it takes before the \(i^{th}\) likely voter agrees to take the survey after the previous likely voter takes the survey.",The MLE for p is then given by,4, \(\hat{p} = \bar{x}\) (the average of the observed x’s),\(\hat{p} = \text{max}\{x_i\}\) (the maximum of the observed x’s),\(\hat{p} = 1 / \bar{x}\) (the inverse of the average of the observed x’s),\(\hat{p} = \text{min}\{x_i\}\) (the minimum of the observed x’s),,,\(\hat{p} = 1 / \bar{x}\) (the inverse of the average of the observed x’s),Find p so l’= 0 and l” < 0 where l is the log likelihood and the derivative is w.r.t. p
6,"A polling company wants to know how many random calls it must make on average before reaching a person who is likely to vote in the next election and agrees to take their brief survey.  To estimate this quantity they will use their normal procedure 20 times and collect data on  \(X_1, X_2,…, X_{20}\) where \(X_i\) = how many calls it takes before the \(i^{th}\) likely voter agrees to take the survey after the previous likely voter takes the survey.","Finally, to answer the polling company’s question about estimating how many random calls it must make on average per respondent using maximum likelihood, we would find the ",4,MLE of 1/p which is \( 1 / \hat{p}  = \bar{x}\) (the average of the observed x’s),MLE of 1/p which is \( 1/ \hat{p} = 1/ \bar{x} \) (where \(\bar{x}\) = the average of the observed x’s),MLE of the median m which is \(\tilde{m}\) (the median of the x’s),MLE of the derivative of the log likelihood,,,MLE of 1/p which is \( 1 / \hat{p}  = \bar{x}\) (the average of the observed x’s),Use the invariance property of the MLE
7,"The time between earthquakes, X, depends on a parameter \(\theta\) that is associated with the sensitivity of the hardware used to detect them so that X follows the pdf \(f(x)=\begin{cases}\theta^2 xe^{-\theta x} & \text{ for } x > 0 \\ 0 & \text{otherwise}\end{cases}\) The times for three independent earthquakes are recorded and found (in days) to be 87, 565, and 122.",What is the likelihood function?,4,\( f(x)=\begin{cases}\theta^{2} xe^{- \theta x} & \text{ for $x > 0$ } \\ 0 & \text{otherwise} \end{cases} \),\( 774 \cdot \theta^{6} e^{-3\theta}\),\(\theta^{6}x^3 e^{-5 \theta x}\),"\( 5,996,910\cdot \theta^{6}e^{-774\theta}\)",,,"\( 5,996,910\cdot \theta^{6}e^{-774\theta}\)",3 i.i.d. observations give a product likelihood
7,"The time between earthquakes, X, depends on a parameter \(\theta\) that is associated with the sensitivity of the hardware used to detect them so that X follows the pdf \(f(x)=\begin{cases}\theta^2 xe^{-\theta x} & \text{ for } x > 0 \\ 0 & \text{otherwise}\end{cases}\) The times for three independent earthquakes are recorded and found (in days) to be 87, 565, and 122.","What is \(\hat{\theta}\), the MLE of \(\theta\)?",4,129,\(\frac{1}{129}\),"\(\frac{5,996,910}{774}\)","\(\frac{5,996,910}{3!}\)",,,\(\frac{1}{129}\),Find \(\theta\) so l’= 0 and l” <0 where l is the log likelihood and the derivative is w.r.t. \(\theta\)